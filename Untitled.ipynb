{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f151f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class evaluate_model:\n",
    "\t\"\"\"\n",
    "\t     This class will be used to evaluate the models performance\n",
    "\t     based on the certain metrics.\n",
    "\n",
    "\t    Written By: JSL\n",
    "        Version: 1.0\n",
    "        Revisions: None\n",
    "\n",
    "\t\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.file_path = \"prediction_logs/ModelEvaluation.txt\"\n",
    "\t\t#self.logger_object = App_Logger()\n",
    "\t\tself.path = \"Training_Data_prediction/TestModelprediction.csv\"\n",
    "\t\tself.prod_metrics = {}\n",
    "\t\tself.test_metrics = {}\n",
    "\t\tself.mode = ['Test','Production']\n",
    "\t\t#self.input_file_path = \"PredictionFileFromDB/InputFile.csv\"\n",
    "\n",
    "\tdef model_prediction(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\t Method Name: model_prediction\n",
    "\t\t     Description: This method will be used to evaluate the performance of the model\n",
    "\t\t      on the new training data.\n",
    "\n",
    "\t\t     On output: Models performance metrics\n",
    "\t\t     Failure: Raises an exception\n",
    "\n",
    "\t\t     Written by: JSL\n",
    "\t\t     Revision: None\n",
    "\t\t     Version: 1.0\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\tfor mode in self.mode:\n",
    "\t\t\t\tif mode == 'Test':\n",
    "\n",
    "\t\t\t\t\tself.file_object = open(self.file_path,\"a+\")\n",
    "\t\t\t\t\tself.logger_object.log(self.file_object,\"Entered inside Test model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\tself.file_object.close()\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestModelprediction.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestModelprediction.csv\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestCluster_data.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\t\t\t\t\tself.data_op = Data_Getter(self.file_object,self.logger_object)    ##initializing the object of data getter class\n",
    "\t\t\t\t\tself.data = self.data_op.get_data()     ###loading the training data\n",
    "\n",
    "\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\tX1 = preprocess.remove_columns(self.data,[\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\tX,Y = preprocess.separate_label_features(X1,\"Output\")\n",
    "\n",
    "\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\tX2 = preprocess.remove_columns(X_new,self.cols_drop_list)\n",
    "\n",
    "\t\t\t\t\tself.file_op = File_operation(self.file_path,self.logger_object)\n",
    "\n",
    "\t\t\t\t\tkmeans = self.file_op.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t#clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\tX2[\"True\"] = Y\n",
    "\n",
    "\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\n",
    "\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t#cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\tcluster_data = X2.drop([\"True\"],axis =1)\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"],axis =1)\n",
    "\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"],axis = 1)\n",
    "\t\t\t\t\t\tmodel_name = self.file_op.find_correct_model_file(i)\n",
    "\t\t\t\t\t\tmodel = self.file_op.load_model(model_name)\n",
    "\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names,result,Y_true)),columns = [\"Wafer\",\"Prediction\",\"Y_True\"])\n",
    "\t\t\t\t\tresult.to_csv(self.path,index = None,header = True,mode = 'a+')\n",
    "\t\t\t\t\treturn X2.to_csv(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.file_object = open(self.file_path, \"a+\")\n",
    "\t\t\t\t\tself.logger_object.log(self.file_object,\"Entered inside production model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionModelprediction.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionModelprediction.csv\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionCluster_data.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\t\t\t\t\tself.data_op = Data_Getter(self.file_object,self.logger_object)  ##initializing the object of data getter class\n",
    "\t\t\t\t\tself.data = self.data_op.get_data()  ###loading the training data\n",
    "\n",
    "\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\tX1 = preprocess.remove_columns(self.data, [\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\tX, Y = preprocess.separate_label_features(X1, \"Output\")\n",
    "\n",
    "\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\tX2 = preprocess.remove_columns(X_new, self.cols_drop_list)\n",
    "\n",
    "\t\t\t\t\tself.file_prod = File_operation_prod(self.file_path, self.logger_object)\n",
    "\n",
    "\t\t\t\t\tkmeans = self.file_prod.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t# clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\tX2[\"True\"] = Y\n",
    "\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\n",
    "\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t#cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\tcluster_data = X2.drop([\"True\"],axis =1)\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"],axis =1)\n",
    "\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"],axis = 1)\n",
    "\t\t\t\t\t\tmodel_name = self.file_prod.find_correct_model_file(i)\n",
    "\t\t\t\t\t\tmodel = self.file_prod.load_model(model_name)\n",
    "\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names,result,Y_true)),columns = [\"Wafer\",\"Prediction\",\"Y_True\"])\n",
    "\t\t\t\t\tresult.to_csv(path = \"Training_Data_prediction/ProductionModelprediction.csv\",index = None,header = True,mode = 'a+')\n",
    "\t\t\t\t\treturn X2.to_csv(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ec57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf24091b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data_Getter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m evaluate_model()\n\u001b[1;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 145\u001b[0m, in \u001b[0;36mevaluate_model.model_prediction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \t\t\t\u001b[38;5;28;01mreturn\u001b[39;00m X2\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining_Data_prediction/ProductionCluster_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 145\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[5], line 47\u001b[0m, in \u001b[0;36mevaluate_model.model_prediction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining_Data_prediction/TestCluster_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     46\u001b[0m \tos\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining_Data_prediction/TestCluster_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_op \u001b[38;5;241m=\u001b[39m \u001b[43mData_Getter\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_object,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_object)    \u001b[38;5;66;03m##initializing the object of data getter class\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_op\u001b[38;5;241m.\u001b[39mget_data()     \u001b[38;5;66;03m###loading the training data\u001b[39;00m\n\u001b[0;32m     50\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m Preprocessing()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data_Getter' is not defined"
     ]
    }
   ],
   "source": [
    "a = evaluate_model()\n",
    "a.model_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a66b5beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "l = [1,2]\n",
    "for i in l:\n",
    "    if i == 1:\n",
    "        print(4)\n",
    "    elif i == 2:\n",
    "        print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baf606e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode= ('Test', 'Production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b46b2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for mode in mode:\n",
    "    if mode == 'Test':\n",
    "        print(4)\n",
    "    elif mode == 'Production':\n",
    "        print(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.file_object = open(self.file_path,\"a+\")\n",
    "\t\t\t\t\tself.logger_object.log(self.file_object,\"Entered inside Test model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\t#self.file_object.close()\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestModelprediction.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestModelprediction.csv\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestCluster_data.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\t\t\t\t\tself.data_op = Data_Getter(self.file_object,self.logger_object)    ##initializing the object of data getter class\n",
    "\t\t\t\t\tself.data = self.data_op.get_data()     ###loading the training data\n",
    "\n",
    "\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\tX1 = preprocess.remove_columns(self.data,[\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\tX,Y = preprocess.separate_label_features(X1,\"Output\")\n",
    "\n",
    "\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\tX2 = preprocess.remove_columns(X_new,self.cols_drop_list)\n",
    "\n",
    "\t\t\t\t\tself.file_op = File_operation(self.file_path,self.logger_object)\n",
    "\n",
    "\t\t\t\t\tkmeans = self.file_op.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t#clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\tX2[\"True\"] = Y\n",
    "\n",
    "\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\n",
    "\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t#cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\tcluster_data = X2.drop([\"True\"],axis =1)\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"],axis =1)\n",
    "\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"],axis = 1)\n",
    "\t\t\t\t\t\tmodel_name = self.file_op.find_correct_model_file(i)\n",
    "\t\t\t\t\t\tmodel = self.file_op.load_model(model_name)\n",
    "\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names,result,Y_true)),columns = [\"Wafer\",\"Prediction\",\"Y_True\"])\n",
    "\t\t\t\t\tresult.to_csv(self.path,index = None,header = True,mode = 'a+')\n",
    "\t\t\t\t\treturn X2.to_csv(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.file_object = open(self.file_path, \"a+\")\n",
    "\t\t\t\t\tself.logger_object.log(self.file_object,\"Entered inside production model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionModelprediction.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionModelprediction.csv\")\n",
    "\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionCluster_data.csv\"):\n",
    "\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\t\t\t\t\tself.data_op = Data_Getter(self.file_object,self.logger_object)  ##initializing the object of data getter class\n",
    "\t\t\t\t\tself.data = self.data_op.get_data()  ###loading the training data\n",
    "\n",
    "\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\tX1 = preprocess.remove_columns(self.data, [\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\tX, Y = preprocess.separate_label_features(X1, \"Output\")\n",
    "\n",
    "\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\tX2 = preprocess.remove_columns(X_new, self.cols_drop_list)\n",
    "\n",
    "\t\t\t\t\tself.file_prod = File_operation_prod(self.file_path, self.logger_object)\n",
    "\n",
    "\t\t\t\t\tkmeans = self.file_prod.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t# clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\tX2[\"True\"] = Y\n",
    "\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\n",
    "\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t#cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\tcluster_data = X2.drop([\"True\"],axis =1)\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"],axis =1)\n",
    "\n",
    "\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"],axis = 1)\n",
    "\t\t\t\t\t\tmodel_name = self.file_prod.find_correct_model_file(i)\n",
    "\t\t\t\t\t\tmodel = self.file_prod.load_model(model_name)\n",
    "\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names,result,Y_true)),columns = [\"Wafer\",\"Prediction\",\"Y_True\"])\n",
    "\t\t\t\t\tresult.to_csv(path = \"Training_Data_prediction/ProductionModelprediction.csv\",index = None,header = True,mode = 'a+')\n",
    "\t\t\t\t\treturn X2.to_csv(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86011a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from application_logging.logger import App_Logger\n",
    "from data_preprocessing.data_preprocessing import Preprocessing\n",
    "from data_ingestion.data_loader_prediction import data_getter_prediction\n",
    "from data_ingestion.data_loader import Data_Getter\n",
    "from file_operations.file_methods import File_operation\n",
    "from prediction_raw_data_validation.prediction_raw_data_validation import prediction_data_validation\n",
    "#from prediction_raw_data_validation.prediction_raw_data_validation import prediction_data_validation\n",
    "from sklearn.metrics import precision_score,recall_score,roc_auc_score,accuracy_score,f1_score\n",
    "from file_operations.model_production import File_operation_prod\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class evaluate_model:\n",
    "\t\"\"\"\n",
    "\t     This class will be used to evaluate the models performance\n",
    "\t     based on the certain metrics.\n",
    "\n",
    "\t    Written By: JSL\n",
    "        Version: 1.0\n",
    "        Revisions: None\n",
    "\n",
    "\t\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.file_path = \"prediction_logs/ModelEvaluation.txt\"\n",
    "\t\tself.logger_object = App_Logger()\n",
    "\t\tself.path = \"Training_Data_prediction/TestModelprediction.csv\"\n",
    "\n",
    "\t\tself.test_metrics = {}\n",
    "\t\tself.prod_metrics = {}\n",
    "\t\tself.mode = ['Test', 'Production']\n",
    "\n",
    "\t\t#self.input_file_path = \"PredictionFileFromDB/InputFile.csv\"\n",
    "\n",
    "\tdef model_prediction(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\t Method Name: model_prediction\n",
    "\t\t     Description: This method will be used to evaluate the performance of the model\n",
    "\t\t      on the new training data.\n",
    "\n",
    "\t\t     On output: Models performance metrics\n",
    "\t\t     Failure: Raises an exception\n",
    "\n",
    "\t\t     Written by: JSL\n",
    "\t\t     Revision: None\n",
    "\t\t     Version: 1.0\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\n",
    "\t\t\tfor m in self.mode:\n",
    "\t\t\t\t\tprint(m)\n",
    "\t\t\t\t\tif m == 'Test':\n",
    "\t\t\t\t\t\tself.file_object = open(self.file_path,\"a+\")\n",
    "\t\t\t\t\t\tself.logger_object.log(self.file_object,\"Entered inside Test model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\t\tself.file_object.close()\n",
    "\t\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestModelprediction.csv\"):\n",
    "\t\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestModelprediction.csv\")\n",
    "\t\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/TestCluster_data.csv\"):\n",
    "\t\t\t\t\t\t\tos.remove(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\t\t\t\t\t\tself.data_op = Data_Getter(self.file_object,self.logger_object)  ##initializing the object of data getter class\n",
    "\t\t\t\t\t\tself.data = self.data_op.get_data()  ###loading the training data\n",
    "\n",
    "\t\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\t\tX1 = preprocess.remove_columns(self.data, [\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\t\tX, Y = preprocess.separate_label_features(X1, \"Output\")\n",
    "\n",
    "\t\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\t\tX2 = preprocess.remove_columns(X_new, self.cols_drop_list)\n",
    "\t\t\t\t\t\tself.file_op = File_operation(self.file_path, self.logger_object)\n",
    "\n",
    "\t\t\t\t\t\tkmeans = self.file_op.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t\t# clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\t\tX2[\"True\"] = Y\n",
    "\t\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\t\tX2[\"True\"] = Y\n",
    "\n",
    "\t\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\t\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t\t# cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\t\tcluster_data = X2.drop([\"True\"], axis=1)\n",
    "\t\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"], axis=1)\n",
    "\t\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"], axis=1)\n",
    "\t\t\t\t\t\t\tmodel_name = self.file_op.find_correct_model_file(i)\n",
    "\t\t\t\t\t\t\tmodel = self.file_op.load_model(model_name)\n",
    "\t\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names, result, Y_true)),columns=[\"Wafer\", \"Prediction\", \"Y_True\"])\n",
    "\t\t\t\t\t\tresult.to_csv(self.path, index=None, header=True, mode='a+')\n",
    "\t\t\t\t\t\tX2.to_csv(\"Training_Data_prediction/TestCluster_data.csv\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tself.file_object = open(self.file_path, \"a+\")\n",
    "\t\t\t\t\t\tself.logger_object.log(self.file_object,\n",
    "\t\t\t\t\t\t                       \"Entered inside production model performance method of the evaluate_model class\")\n",
    "\t\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionModelprediction.csv\"):\n",
    "\t\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionModelprediction.csv\")\n",
    "\t\t\t\t\t\tif os.path.exists(\"Training_Data_prediction/ProductionCluster_data.csv\"):\n",
    "\t\t\t\t\t\t\tos.remove(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\t\t\t\t\t\tself.data_op = Data_Getter(self.file_object,\n",
    "\t\t\t\t\t\t                           self.logger_object)  ##initializing the object of data getter class\n",
    "\t\t\t\t\t\tself.data = self.data_op.get_data()  ###loading the training data\n",
    "\n",
    "\t\t\t\t\t\tpreprocess = Preprocessing()\n",
    "\t\t\t\t\t\tX1 = preprocess.remove_columns(self.data, [\"Unnamed: 0\"])\n",
    "\n",
    "\t\t\t\t\t\tX, Y = preprocess.separate_label_features(X1, \"Output\")\n",
    "\n",
    "\t\t\t\t\t\tself.is_null_present = preprocess.is_null_present(X)\n",
    "\n",
    "\t\t\t\t\t\tif self.is_null_present:\n",
    "\t\t\t\t\t\t\tX_new = preprocess.missing_value_imputation(X)\n",
    "\n",
    "\t\t\t\t\t\tself.cols_drop_list = preprocess.cols_with_zero_std_deviation(X_new)\n",
    "\n",
    "\t\t\t\t\t\tX2 = preprocess.remove_columns(X_new, self.cols_drop_list)\n",
    "\n",
    "\t\t\t\t\t\tself.file_prod = File_operation_prod(self.file_path, self.logger_object)\n",
    "\n",
    "\t\t\t\t\t\tkmeans = self.file_prod.load_model(\"KMeans\")\n",
    "\n",
    "\t\t\t\t\t\tclusters = kmeans.predict(X2.drop(['Wafer'], axis=1))\n",
    "\t\t\t\t\t\t# clusters = kmeans.predict(X2.drop([\"Wafer\"], axis=1))\n",
    "\n",
    "\t\t\t\t\t\tX2[\"clusters\"] = clusters\n",
    "\t\t\t\t\t\tX2[\"True\"] = Y\n",
    "\t\t\t\t\t\tlist_of_clusters = X2[\"clusters\"].unique()\n",
    "\n",
    "\t\t\t\t\t\tfor i in list_of_clusters:\n",
    "\t\t\t\t\t\t\tcluster_data = X2[X2[\"clusters\"] == i]\n",
    "\t\t\t\t\t\t\t# cluster_names = list(cluster_data[\"clusters\"])\n",
    "\t\t\t\t\t\t\tY_true = list(X2[\"True\"])\n",
    "\t\t\t\t\t\t\twafer_names = list(X2[\"Wafer\"])\n",
    "\t\t\t\t\t\t\tcluster_data = X2.drop([\"True\"], axis=1)\n",
    "\t\t\t\t\t\t\tcluster_data = cluster_data.drop([\"Wafer\"], axis=1)\n",
    "\n",
    "\t\t\t\t\t\t\tcluster_data = cluster_data.drop([\"clusters\"], axis=1)\n",
    "\t\t\t\t\t\t\tmodel_name = self.file_prod.find_correct_model_file(i)\n",
    "\t\t\t\t\t\t\tmodel = self.file_prod.load_model(model_name)\n",
    "\t\t\t\t\t\t\tresult = list(model.predict(cluster_data))\n",
    "\t\t\t\t\t\t\tresult = pd.DataFrame(list(zip(wafer_names, result, Y_true)),columns=[\"Wafer\", \"Prediction\", \"Y_True\"])\n",
    "\t\t\t\t\t\tresult.to_csv(\"Training_Data_prediction/ProductionModelprediction.csv\", index=None,header=True, mode='a+')\n",
    "\t\t\t\t\t\tX2.to_csv(\"Training_Data_prediction/ProductionCluster_data.csv\")\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tdef calculate_metrics_score_for_test(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\tMethod Name:calculate_metrics_score\n",
    "\t\t\tDescription: This method will be used to calculate metrics scores for\n",
    "\t\t\tevaluating the performance of models with respect to their clusters.\n",
    "\n",
    "\t\t\tWritten by: JSL\n",
    "\t\t    Revision: None\n",
    "\t\t    Version: 1.0\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\tself.data = \"Training_Data_prediction/TestCluster_data.csv\"\n",
    "\t\t\t#self.data = self.model_prediction()\n",
    "\n",
    "\n",
    "\t\t\tresult = \"Training_Data_prediction/TestModelprediction.csv\"\n",
    "\t\t\tself.df = pd.read_csv(self.data)\n",
    "\t\t\tclusters = self.df[\"clusters\"]\n",
    "\t\t\tself.df_result = pd.read_csv(\"Training_Data_prediction/TestModelprediction.csv\")\n",
    "\t\t\tself.df_result[\"Clusters\"] = clusters\n",
    "\t\t\tlist_of_cluster = self.df_result[\"Clusters\"].unique()\n",
    "\t\t\tfor i in list_of_cluster:\n",
    "\t\t\t\tcluster_data = self.df_result[self.df_result[\"Clusters\"] == i]\n",
    "\t\t\t\tif len(cluster_data[\"Y_True\"].unique()) == 1:\n",
    "\t\t\t\t\tself.test_metrics['Test_accuracy_score::'+ str(i)] = str(accuracy_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"]))\n",
    "\t\t\t\t\tprint(\"accuracy_score_cluster_no.:%s\"%i + \" = \" + str(accuracy_score(accuracy_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"]))))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.test_metrics['Test_roc_auc_score_cluster_no::'+ str(i)] = str(roc_auc_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"]))\n",
    "\t\t\t\t\tprint(\"roc_auc_score_cluster_no.: %s\" %i + \" = \" + str(roc_auc_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"])))\n",
    "\t\t\t\t\tprint(\"precision_score_cluster_no.: %s\" % i + \" = \" + str(precision_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"])))\n",
    "\t\t\t\t\tprint(\"recall_score_cluster_no.: %s\" % i + \" = \" + str(recall_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"])))\n",
    "\n",
    "\t\t\treturn self.test_metrics\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e\n",
    "\n",
    "\tdef calculate_metrics_score_for_production(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\tMethod Name:calculate_metrics_score\n",
    "\t\t\tDescription: This method will be used to calculate metrics scores for\n",
    "\t\t\tevaluating the performance of models with respect to their clusters.\n",
    "\n",
    "\t\t\tWritten by: JSL\n",
    "\t\t    Revision: None\n",
    "\t\t    Version: 1.0\n",
    "\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\n",
    "\t\t\tself.data = \"Training_Data_prediction/ProductionCluster_data.csv\"\n",
    "\t\t\t#self.data = self.model_prediction()\n",
    "\n",
    "\t\t\tresult = \"Training_Data_prediction/ProductionModelprediction.csv\"\n",
    "\t\t\tself.df = pd.read_csv(self.data)\n",
    "\t\t\tclusters = self.df[\"clusters\"]\n",
    "\t\t\tself.df_result = pd.read_csv(\"Training_Data_prediction/ProductionModelprediction.csv\")\n",
    "\t\t\tself.df_result[\"Clusters\"] = clusters\n",
    "\t\t\tlist_of_cluster = self.df_result[\"Clusters\"].unique()\n",
    "\t\t\tfor i in list_of_cluster:\n",
    "\t\t\t\tcluster_data = self.df_result[self.df_result[\"Clusters\"] == i]\n",
    "\t\t\t\tif len(cluster_data[\"Y_True\"].unique()) == 1:\n",
    "\t\t\t\t\tself.prod_metrics['Prod_accuracy_score::' + str(i)] = str(accuracy_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"]))\n",
    "\t\t\t\t\tprint(\"prod_accuracy_score_cluster_no.: %s\"%i + \" = \" + str(accuracy_score(accuracy_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"]))))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.prod_metrics['Prod_roc_auc_score_cluster_no::' + str(i)] = str(roc_auc_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"]))\n",
    "\n",
    "\t\t\t\t\tprint(\"prod_roc_auc_score_cluster_no.: %s\" %i + \" = \" + str(roc_auc_score(cluster_data[\"Y_True\"],cluster_data[\"Prediction\"])))\n",
    "\t\t\t\t\tprint(\"prod_precision_score_cluster_no.: %s\" % i + \" = \" + str(precision_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"])))\n",
    "\t\t\t\t\tprint(\"prod_recall_score_cluster_no.: %s\" % i + \" = \" + str(recall_score(cluster_data[\"Y_True\"], cluster_data[\"Prediction\"])))\n",
    "\t\t\t\t\t#print('a:' + self.prod_metrics['Prod_roc_auc_score_cluster_no::0'])\n",
    "\n",
    "\t\t\treturn self.prod_metrics\n",
    "\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e\n",
    "\n",
    "\n",
    "\tdef compare_models_performance(self):\n",
    "\t\ta_prod_key = []\n",
    "\t\tb_prod_val = []\n",
    "\t\ta_test_key = []\n",
    "\t\tb_test_val = []\n",
    "\n",
    "\t\tkey_invalid = []\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tfor i,j in self.prod_metrics.items():\n",
    "\t\t\t\ta_prod_key.append(i)\n",
    "\t\t\t\tb_prod_val.append(j)\n",
    "\t\t\tfor i, j in self.test_metrics.items():\n",
    "\t\t\t\ta_test_key.append(i)\n",
    "\t\t\t\tb_test_val.append(j)\n",
    "\t\t\tif len(a_prod_key) == len(a_test_key):\n",
    "\t\t\t\tfor i in a_prod_key:\n",
    "\t\t\t\t\tif i in a_test_key:\n",
    "\t\t\t\t\t\tif self.prod_metrics[i] < self.test_metrics[i]:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\telif self.prod_metrics[i] > self.test_metrics[i]:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\telif i not in a_test_key:\n",
    "\t\t\t\t\t\tkey_invalid.append(i)\n",
    "\n",
    "\t\t\telif len(a_prod_key) != len(a_test_key):\n",
    "\t\t\t\tprint('Production models clusters are different than the testing models')\n",
    "\n",
    "\t\t\tif len(key_invalid) != 0:\n",
    "\t\t\t\tprint('model invalid')\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\traise e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = evaluate_model()\n",
    "a.model_prediction()\n",
    "a.calculate_metrics_score_for_production()\n",
    "a.calculate_metrics_score_for_test()\n",
    "print(\"done\")\n",
    "print(a.prod_metrics)\n",
    "print(a.test_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8067f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['prakhar','raghav','harshit']\n",
    "b = ['prakhar','raghav','harshit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beaf7777",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;129;01min\u001b[39;00m \u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m2\u001b[39m:]:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4511dfb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prakhar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(a)):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a_key[i][\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;129;01min\u001b[39;00m b_key[i][\u001b[38;5;241m2\u001b[39m:]:\n\u001b[1;32m----> 8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma_key\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prakhar'"
     ]
    }
   ],
   "source": [
    "a = {'F_prakhar':1, 'F_raghav':2, 'F_harshit':3}\n",
    "b = {'P_prakhar':0, 'P_raghav':4, 'P_harshit':1}\n",
    "a_key = ['F_prakhar','F_raghav','F_harshit']\n",
    "b_key = ['P_prakhar','P_raghav','P_harshit']\n",
    "\n",
    "for i in range(len(a)):\n",
    "    if a_key[i][2:] in b_key[i][2:]:\n",
    "        print(a[a_key[i][2:]])\n",
    "        #if a[a_key[i][2:]] < b[a_key[i][2:]]:\n",
    "            #print(a[a_key[i]])\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f83f29f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: closing parenthesis '}' does not match opening parenthesis '[' (3088819949.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"{a_key[i]} value ({a[a_key[i][2:]}), is less than {b_key[i]} value ({b[b_key[i][2:]])}\")\u001b[0m\n\u001b[1;37m                                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: closing parenthesis '}' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "a = {'F_prakhar': 1, 'F_raghav': 2, 'F_harshit': 3}\n",
    "b = {'P_prakhar': 0, 'P_raghav': 4, 'P_harshit': 1}\n",
    "a_key = ['F_prakhar', 'F_raghav', 'F_harshit']\n",
    "b_key = ['P_prakhar', 'P_raghav', 'P_harshit']\n",
    "\n",
    "for i in range(len(a_key)):  # Use the length of a_key to iterate over the keys\n",
    "    if a_key[i][2:] in b_key[i][2:]:\n",
    "        if a[a_key[i][2:]] < b[b_key[i][2:]]:\n",
    "            print(f\"{a_key[i]} value ({a[a_key[i][2:]}), is less than {b_key[i]} value ({b[b_key[i][2:]])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa540007",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prakhar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(a_key)):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a_key[i][\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;129;01min\u001b[39;00m b_key[i][\u001b[38;5;241m2\u001b[39m:]:\n\u001b[1;32m----> 8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma_key\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m b[b_key[i][\u001b[38;5;241m2\u001b[39m:]]:\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;28mprint\u001b[39m(a[a_key[i][\u001b[38;5;241m2\u001b[39m:]])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prakhar'"
     ]
    }
   ],
   "source": [
    "a = {'F_prakhar': 1, 'F_raghav': 2, 'F_harshit': 3}\n",
    "b = {'P_prakhar': 0, 'P_raghav': 4, 'P_harshit': 1}\n",
    "a_key = ['F_prakhar', 'F_raghav', 'F_harshit']\n",
    "b_key = ['P_prakhar', 'P_raghav', 'P_harshit']\n",
    "\n",
    "for i in range(len(a_key)):\n",
    "    if a_key[i][2:] in b_key[i][2:]:\n",
    "        if a[a_key[i][2:]] < b[b_key[i][2:]]:\n",
    "            print(a[a_key[i][2:]])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fd595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
